# Comparative Analysis of Transfer Learning Models for Breast Cancer Classification
This repository contains the codebase for our paper, **"Comparative Analysis of Transfer Learning Models for Breast Cancer Classification"**. Our study explores and evaluates various deep learning architectures for accurately classifying histopathological images, focusing on distinguishing **Invasive Ductal Carcinoma (IDC)** from non-IDC, with the goal of enhancing breast cancer diagnosis.
## Project Overview

Histopathology image classification plays a critical role in the early detection and precise diagnosis of breast cancer. In this work, we rigorously compare the performance of eight prominent transfer learning models—**ResNet-50, DenseNet-121, ResNeXt-50, Vision Transformer (ViT), GoogLeNet (Inception v3), EfficientNet, MobileNet, and SqueezeNet**—on a dataset of 277,524 image patches. Each model is evaluated for:
- **Accuracy**
- **Computational Efficiency**
- **Robustness**

Key findings highlight the superior accuracy of attention-based models, particularly the **Vision Transformer (ViT)**, which achieved a validation accuracy of **93%**, outperforming traditional convolutional networks. This repository provides scripts and setup instructions to reproduce our results, demonstrating the practical application of advanced machine learning techniques in clinical settings.

