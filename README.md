Comparative Analysis of Transfer Learning Models for Breast Cancer Classification

This repository contains the codebase for our paper "Comparative Analysis of Transfer Learning Models for Breast Cancer Classification". Our study explores the use of various deep learning architectures for accurately classifying histopathological images in the context of breast cancer diagnosis, specifically focusing on distinguishing Invasive Ductal Carcinoma (IDC) from non-IDC.

Project Overview
Histopathology image classification plays a critical role in the early detection and precise diagnosis of breast cancer. In this work, we rigorously compared the performance of eight prominent transfer learning modelsâ€”ResNet-50, DenseNet-121, ResNeXt-50, Vision Transformer (ViT), GoogLeNet (Inception v3), EfficientNet, MobileNet, and SqueezeNet. Using a dataset of 277,524 image patches, we evaluated each model's effectiveness in terms of accuracy, computational efficiency, and robustness.
Key findings highlight the superior accuracy of attention-based models, particularly Vision Transformer (ViT), which achieved a validation accuracy of 93%, outperforming traditional convolutional networks. This repository provides scripts and setup instructions to reproduce our results, demonstrating the practical application of advanced machine learning techniques in clinical settings.

Citation
If you use our code, please cite our paper available at https://arxiv.org/abs/2408.16859

